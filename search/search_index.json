{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"CoreGeth: An Ethereum Protocol Provider \u00b6 An ethereum/go-ethereum downstream effort to make the Ethereum Protocol accessible and extensible for a diverse ecosystem. Priority is given to reducing opinions around chain configuration, IP-based feature implementations, and API predictability. Upstream development from ethereum/go-ethereum is merged to this repository regularly, usually at every upstream tagged release. Every effort is made to maintain seamless compatibility with upstream source, including compatible RPC, JS, and CLI APIs, data storage locations and schemas, and, of course, interoperable node protocols. Applicable bug reports, bug fixes, features, and proposals should be made upstream whenever possible. Network/provider comparison \u00b6 Networks supported by the respective core-geth packaged geth program. Ticker Consensus Network core-geth ethereum/go-ethereum ETC Ethereum Classic ETH Ethereum (Foundation) ETSC Ethereum Social ESN EtherSocial MIX Mix ELLA Ellaism 1 MUSIC Musicoin 2 - Private chains Mordor (Geth+Parity ETH PoW Testnet) Morden (Geth+Parity ETH PoW Testnet) Ropsten (Geth+Parity ETH PoW Testnet) Rinkeby (Geth-only ETH PoA Testnet) Goerli (Geth+Parity ETH PoA Testnet) Kotti (Geth+Parity ETC PoA Testnet) Kovan (Parity-only ETH PoA Testnet) Tobalaba (EWF Testnet) Ephemeral development PoA network = Proof of Work = Proof of Authority 1 : This is originally an Ellaism Project . However, A recent hard fork makes Ellaism not feasible to support with go-ethereum any more. Existing Ellaism users are asked to switch to Parity . 2 : Network not supported by default, but network configuration is possible. Make a PR!","title":"Home"},{"location":"#coregeth-an-ethereum-protocol-provider","text":"An ethereum/go-ethereum downstream effort to make the Ethereum Protocol accessible and extensible for a diverse ecosystem. Priority is given to reducing opinions around chain configuration, IP-based feature implementations, and API predictability. Upstream development from ethereum/go-ethereum is merged to this repository regularly, usually at every upstream tagged release. Every effort is made to maintain seamless compatibility with upstream source, including compatible RPC, JS, and CLI APIs, data storage locations and schemas, and, of course, interoperable node protocols. Applicable bug reports, bug fixes, features, and proposals should be made upstream whenever possible.","title":"CoreGeth: An Ethereum Protocol Provider"},{"location":"#networkprovider-comparison","text":"Networks supported by the respective core-geth packaged geth program. Ticker Consensus Network core-geth ethereum/go-ethereum ETC Ethereum Classic ETH Ethereum (Foundation) ETSC Ethereum Social ESN EtherSocial MIX Mix ELLA Ellaism 1 MUSIC Musicoin 2 - Private chains Mordor (Geth+Parity ETH PoW Testnet) Morden (Geth+Parity ETH PoW Testnet) Ropsten (Geth+Parity ETH PoW Testnet) Rinkeby (Geth-only ETH PoA Testnet) Goerli (Geth+Parity ETH PoA Testnet) Kotti (Geth+Parity ETC PoA Testnet) Kovan (Parity-only ETH PoA Testnet) Tobalaba (EWF Testnet) Ephemeral development PoA network = Proof of Work = Proof of Authority 1 : This is originally an Ellaism Project . However, A recent hard fork makes Ellaism not feasible to support with go-ethereum any more. Existing Ellaism users are asked to switch to Parity . 2 : Network not supported by default, but network configuration is possible. Make a PR!","title":"Network/provider comparison"},{"location":"apis/jsonrpc-apis/","text":"JSON-RPC APIs \u00b6 Programmatically interfacing geth nodes \u00b6 As a developer, sooner rather than later you\u2019ll want to start interacting with geth and the Ethereum Classic network via your own programs and not manually through the console. To aid this, geth has built-in support for a JSON-RPC based APIs ( standard APIs and geth specific APIs ). These can be exposed via HTTP, WebSockets and IPC (UNIX sockets on UNIX based platforms, and named pipes on Windows). The IPC interface is enabled by default and exposes all the APIs supported by geth , whereas the HTTP and WS interfaces need to manually be enabled and only expose a subset of APIs due to security reasons. These can be turned on/off and configured as you\u2019d expect. HTTP based JSON-RPC API options: --http Enable the HTTP-RPC server --http.addr HTTP-RPC server listening interface (default: localhost ) --http.port HTTP-RPC server listening port (default: 8545 ) --http.api API\u2019s offered over the HTTP-RPC interface (default: eth,net,web3 ) --http.corsdomain Comma separated list of domains from which to accept cross origin requests (browser enforced) --ws Enable the WS-RPC server --ws.addr WS-RPC server listening interface (default: localhost ) --ws.port WS-RPC server listening port (default: 8546 ) --ws.api API\u2019s offered over the WS-RPC interface (default: eth,net,web3 ) --ws.origins Origins from which to accept websockets requests --graphql Enable GraphQL on the HTTP-RPC server. Note that GraphQL can only be started if an HTTP server is started as well. --graphql.corsdomain Comma separated list of domains from which to accept cross origin requests (browser enforced) --graphql.vhosts Comma separated list of virtual hostnames from which to accept requests (server enforced). Accepts \u2018*\u2019 wildcard. (default: \u201clocalhost\u201d) --ipcdisable Disable the IPC-RPC server --ipcapi API\u2019s offered over the IPC-RPC interface (default: admin,debug,eth,miner,net,personal,shh,txpool,web3 ) --ipcpath Filename for IPC socket/pipe within the datadir (explicit paths escape it) You\u2019ll need to use your own programming environments\u2019 capabilities (libraries, tools, etc) to connect via HTTP, WS or IPC to a geth node configured with the above flags and you\u2019ll need to speak JSON-RPC on all transports. You can reuse the same connection for multiple requests! Here you can check the available JSON-RPC calls . Attention Please understand the security implications of opening up an HTTP/WS based transport before doing so! Hackers on the internet are actively trying to subvert Ethereum nodes with exposed APIs! Further, all browser tabs can access locally running web servers, so malicious web pages could try to subvert locally available APIs!","title":"JSON-RPC"},{"location":"apis/jsonrpc-apis/#json-rpc-apis","text":"","title":"JSON-RPC APIs"},{"location":"apis/jsonrpc-apis/#programmatically-interfacing-geth-nodes","text":"As a developer, sooner rather than later you\u2019ll want to start interacting with geth and the Ethereum Classic network via your own programs and not manually through the console. To aid this, geth has built-in support for a JSON-RPC based APIs ( standard APIs and geth specific APIs ). These can be exposed via HTTP, WebSockets and IPC (UNIX sockets on UNIX based platforms, and named pipes on Windows). The IPC interface is enabled by default and exposes all the APIs supported by geth , whereas the HTTP and WS interfaces need to manually be enabled and only expose a subset of APIs due to security reasons. These can be turned on/off and configured as you\u2019d expect. HTTP based JSON-RPC API options: --http Enable the HTTP-RPC server --http.addr HTTP-RPC server listening interface (default: localhost ) --http.port HTTP-RPC server listening port (default: 8545 ) --http.api API\u2019s offered over the HTTP-RPC interface (default: eth,net,web3 ) --http.corsdomain Comma separated list of domains from which to accept cross origin requests (browser enforced) --ws Enable the WS-RPC server --ws.addr WS-RPC server listening interface (default: localhost ) --ws.port WS-RPC server listening port (default: 8546 ) --ws.api API\u2019s offered over the WS-RPC interface (default: eth,net,web3 ) --ws.origins Origins from which to accept websockets requests --graphql Enable GraphQL on the HTTP-RPC server. Note that GraphQL can only be started if an HTTP server is started as well. --graphql.corsdomain Comma separated list of domains from which to accept cross origin requests (browser enforced) --graphql.vhosts Comma separated list of virtual hostnames from which to accept requests (server enforced). Accepts \u2018*\u2019 wildcard. (default: \u201clocalhost\u201d) --ipcdisable Disable the IPC-RPC server --ipcapi API\u2019s offered over the IPC-RPC interface (default: admin,debug,eth,miner,net,personal,shh,txpool,web3 ) --ipcpath Filename for IPC socket/pipe within the datadir (explicit paths escape it) You\u2019ll need to use your own programming environments\u2019 capabilities (libraries, tools, etc) to connect via HTTP, WS or IPC to a geth node configured with the above flags and you\u2019ll need to speak JSON-RPC on all transports. You can reuse the same connection for multiple requests! Here you can check the available JSON-RPC calls . Attention Please understand the security implications of opening up an HTTP/WS based transport before doing so! Hackers on the internet are actively trying to subvert Ethereum nodes with exposed APIs! Further, all browser tabs can access locally running web servers, so malicious web pages could try to subvert locally available APIs!","title":"Programmatically interfacing geth nodes"},{"location":"apis/openrpc/","text":"OpenRPC \u00b6 Discovery \u00b6 CoreGeth supports OpenRPC\u2019s Service Discovery method , enabling efficient and well-spec\u2019d JSON RPC interfacing and tooling. This method follows the established JSON RPC patterns, and is accessible via HTTP, WebSocket, IPC, and console servers. To use this method: Example $ curl -X POST -H 'Content-Type: application/json' --data '{\"jsonrpc\":\"2.0\",\"method\":\"rpc_discover\",\"params\":[],\"id\":1}' { \"jsonrpc\" : \"2.0\" , \"id\" : 1 , \"result\" : { \"openrpc\" : \"1.0.10\" , \"info\" : { \"description\" : \"This API lets you interact with an EVM-based client via JSON-RPC\" , \"license\" : { \"name\" : \"Apache 2.0\" , \"url\" : \"https://www.apache.org/licenses/LICENSE-2.0.html\" } , \"title\" : \"Ethereum JSON-RPC\" , \"version\" : \"1.0.0\" } , \"servers\" : [] , \"methods\" : [ { \"description\" : \"Returns the version of the current client\" , \"name\" : \"web3_clientVersion\" , \"params\" : [] , \"result\" : { \"description\" : \"client version\" , \"name\" : \"clientVersion\" , \"schema\" : { \"type\" : \"string\" } } , \"summary\" : \"current client version\" } , [ ... ] Better representation of the discovery result at the OpenRPC playground You can see an example use case of the discovery service in the respective OpenRPC Playground .","title":"OpenRPC"},{"location":"apis/openrpc/#openrpc","text":"","title":"OpenRPC"},{"location":"apis/openrpc/#discovery","text":"CoreGeth supports OpenRPC\u2019s Service Discovery method , enabling efficient and well-spec\u2019d JSON RPC interfacing and tooling. This method follows the established JSON RPC patterns, and is accessible via HTTP, WebSocket, IPC, and console servers. To use this method: Example $ curl -X POST -H 'Content-Type: application/json' --data '{\"jsonrpc\":\"2.0\",\"method\":\"rpc_discover\",\"params\":[],\"id\":1}' { \"jsonrpc\" : \"2.0\" , \"id\" : 1 , \"result\" : { \"openrpc\" : \"1.0.10\" , \"info\" : { \"description\" : \"This API lets you interact with an EVM-based client via JSON-RPC\" , \"license\" : { \"name\" : \"Apache 2.0\" , \"url\" : \"https://www.apache.org/licenses/LICENSE-2.0.html\" } , \"title\" : \"Ethereum JSON-RPC\" , \"version\" : \"1.0.0\" } , \"servers\" : [] , \"methods\" : [ { \"description\" : \"Returns the version of the current client\" , \"name\" : \"web3_clientVersion\" , \"params\" : [] , \"result\" : { \"description\" : \"client version\" , \"name\" : \"clientVersion\" , \"schema\" : { \"type\" : \"string\" } } , \"summary\" : \"current client version\" } , [ ... ] Better representation of the discovery result at the OpenRPC playground You can see an example use case of the discovery service in the respective OpenRPC Playground .","title":"Discovery"},{"location":"core/alltools/","text":"Executables \u00b6 The core-geth project comes with several wrappers/executables found in the cmd directory, and which, with make all , will be built to ./build/bin/ . Command Description geth Our main Ethereum Classic CLI client. It is the entry point into the Ethereum network (main-, test- or private net), capable of running as a full node (default), archive node (retaining all historical state) or a light node (retrieving data live). It can be used by other processes as a gateway into the Ethereum network via JSON RPC endpoints exposed on top of HTTP, WebSocket and/or IPC transports. geth --help and the CLI page for command line options. abigen Source code generator to convert Ethereum contract definitions into easy to use, compile-time type-safe Go packages. It operates on plain Ethereum contract ABIs with expanded functionality if the contract bytecode is also available. However, it also accepts Solidity source files, making development much more streamlined. Please see our Native DApps wiki page for details. bootnode Stripped down version of our Ethereum client implementation that only takes part in the network node discovery protocol, but does not run any of the higher level application protocols. It can be used as a lightweight bootstrap node to aid in finding peers in private networks. evm Developer utility version of the EVM (Ethereum Virtual Machine) that is capable of running bytecode snippets within a configurable environment and execution mode. Its purpose is to allow isolated, fine-grained debugging of EVM opcodes (e.g. evm --code 60ff60ff --debug ). gethrpctest Developer utility tool to support the ethereum/rpc-test test suite which validates baseline conformity to the Ethereum JSON RPC specs. Please see the test suite\u2019s readme for details. rlpdump Developer utility tool to convert binary RLP ( Recursive Length Prefix ) dumps (data encoding used by the Ethereum protocol both network as well as consensus wise) to user-friendlier hierarchical representation (e.g. rlpdump --hex CE0183FFFFFFC4C304050583616263 ).","title":"All tools"},{"location":"core/alltools/#executables","text":"The core-geth project comes with several wrappers/executables found in the cmd directory, and which, with make all , will be built to ./build/bin/ . Command Description geth Our main Ethereum Classic CLI client. It is the entry point into the Ethereum network (main-, test- or private net), capable of running as a full node (default), archive node (retaining all historical state) or a light node (retrieving data live). It can be used by other processes as a gateway into the Ethereum network via JSON RPC endpoints exposed on top of HTTP, WebSocket and/or IPC transports. geth --help and the CLI page for command line options. abigen Source code generator to convert Ethereum contract definitions into easy to use, compile-time type-safe Go packages. It operates on plain Ethereum contract ABIs with expanded functionality if the contract bytecode is also available. However, it also accepts Solidity source files, making development much more streamlined. Please see our Native DApps wiki page for details. bootnode Stripped down version of our Ethereum client implementation that only takes part in the network node discovery protocol, but does not run any of the higher level application protocols. It can be used as a lightweight bootstrap node to aid in finding peers in private networks. evm Developer utility version of the EVM (Ethereum Virtual Machine) that is capable of running bytecode snippets within a configurable environment and execution mode. Its purpose is to allow isolated, fine-grained debugging of EVM opcodes (e.g. evm --code 60ff60ff --debug ). gethrpctest Developer utility tool to support the ethereum/rpc-test test suite which validates baseline conformity to the Ethereum JSON RPC specs. Please see the test suite\u2019s readme for details. rlpdump Developer utility tool to convert binary RLP ( Recursive Length Prefix ) dumps (data encoding used by the Ethereum protocol both network as well as consensus wise) to user-friendlier hierarchical representation (e.g. rlpdump --hex CE0183FFFFFFC4C304050583616263 ).","title":"Executables"},{"location":"core/evmc/","text":"Running Geth with an External VM \u00b6 Geth supports the EVMC VM connector API version 6 as an experimental feature. From PR #57 geth enables an externally defined VM, either EVM or EWASM, via a --vm. -prefixed flag for normal instantiation, and --evmc. for testing. Options include EWASM and EVM shared object libraries, as follows: --vm.ewasm=<path/to/interpreter.so --vm.evm=<path/to/interpreter.so Only EVMC Version 6 is supported, which is compatible with the versions of Hera EWASM <=v0.2.5 and SSVM EWASM >=0.5.0. This implementation may be tested by following the command defined in the Makefile as evmc-test , which tests the implementation against both of these mentioned EWASM libraries against the /tests/ StateTest suite. These tests run exclusively via Github Actions, configured at .github/workflows/evmc.yml . While core-geth supports highly granular EIP/ECIP/xIP chain feature configuration (ie fork feature configs), EVMC does not. EVMC only supports the Fork configurations supported by ethereum/go-ethereum (eg. Byzantium, Constantinople, &c). Thus, the implementation at core-geth of EVMC requires a somewhat arbitrary mapping of granular features as keys toggling entire Ethereum fork configurations. The following code snippet, taken from ./core/vm/evmc.go , handles this translation. // getRevision translates ChainConfig's HF block information into EVMC revision. func getRevision ( env * EVM ) evmc . Revision { n := env . BlockNumber conf := env . ChainConfig () switch { // This is an example of choosing to use an \"abstracted\" idea // about chain config, where I'm choosing to prioritize \"indicative\" features // as identifiers for Fork-Feature-Groups. Note that this is very different // than using Feature-complete sets to assert \"did Forkage.\" case conf . IsEnabled ( conf . GetEIP1884Transition , n ): return evmc . Istanbul case conf . IsEnabled ( conf . GetEIP1283DisableTransition , n ): return evmc . Petersburg case conf . IsEnabled ( conf . GetEIP145Transition , n ): return evmc . Constantinople case conf . IsEnabled ( conf . GetEIP198Transition , n ): return evmc . Byzantium case conf . IsEnabled ( conf . GetEIP155Transition , n ): return evmc . SpuriousDragon case conf . IsEnabled ( conf . GetEIP150Transition , n ): return evmc . TangerineWhistle case conf . IsEnabled ( conf . GetEIP7Transition , n ): return evmc . Homestead default : return evmc . Frontier } } As you can see, individual features, like EIP1884, are translated as proxy signifiers for entire fork configurations (in this case, an Istanbul-featured VM revision). This approach, rather than requiring a complete set of the compositional features for any of these given Ethereum forks, trades a descriptive 1:1 mapping for application flexibility. Pursuing a necessarily complete feature-set -> fork map would presume chain features that are not necessarily relevant to the virtual machine, like block reward configurations, or difficulty configurations, for example. This approach allows applications to use advanced opcodes with the fewest number of incidental restrictions. This approach is not without risk or nuance however; without a solid understanding of customizations here, experiments in customization can result in foot shooting.","title":"EVMC"},{"location":"core/evmc/#running-geth-with-an-external-vm","text":"Geth supports the EVMC VM connector API version 6 as an experimental feature. From PR #57 geth enables an externally defined VM, either EVM or EWASM, via a --vm. -prefixed flag for normal instantiation, and --evmc. for testing. Options include EWASM and EVM shared object libraries, as follows: --vm.ewasm=<path/to/interpreter.so --vm.evm=<path/to/interpreter.so Only EVMC Version 6 is supported, which is compatible with the versions of Hera EWASM <=v0.2.5 and SSVM EWASM >=0.5.0. This implementation may be tested by following the command defined in the Makefile as evmc-test , which tests the implementation against both of these mentioned EWASM libraries against the /tests/ StateTest suite. These tests run exclusively via Github Actions, configured at .github/workflows/evmc.yml . While core-geth supports highly granular EIP/ECIP/xIP chain feature configuration (ie fork feature configs), EVMC does not. EVMC only supports the Fork configurations supported by ethereum/go-ethereum (eg. Byzantium, Constantinople, &c). Thus, the implementation at core-geth of EVMC requires a somewhat arbitrary mapping of granular features as keys toggling entire Ethereum fork configurations. The following code snippet, taken from ./core/vm/evmc.go , handles this translation. // getRevision translates ChainConfig's HF block information into EVMC revision. func getRevision ( env * EVM ) evmc . Revision { n := env . BlockNumber conf := env . ChainConfig () switch { // This is an example of choosing to use an \"abstracted\" idea // about chain config, where I'm choosing to prioritize \"indicative\" features // as identifiers for Fork-Feature-Groups. Note that this is very different // than using Feature-complete sets to assert \"did Forkage.\" case conf . IsEnabled ( conf . GetEIP1884Transition , n ): return evmc . Istanbul case conf . IsEnabled ( conf . GetEIP1283DisableTransition , n ): return evmc . Petersburg case conf . IsEnabled ( conf . GetEIP145Transition , n ): return evmc . Constantinople case conf . IsEnabled ( conf . GetEIP198Transition , n ): return evmc . Byzantium case conf . IsEnabled ( conf . GetEIP155Transition , n ): return evmc . SpuriousDragon case conf . IsEnabled ( conf . GetEIP150Transition , n ): return evmc . TangerineWhistle case conf . IsEnabled ( conf . GetEIP7Transition , n ): return evmc . Homestead default : return evmc . Frontier } } As you can see, individual features, like EIP1884, are translated as proxy signifiers for entire fork configurations (in this case, an Istanbul-featured VM revision). This approach, rather than requiring a complete set of the compositional features for any of these given Ethereum forks, trades a descriptive 1:1 mapping for application flexibility. Pursuing a necessarily complete feature-set -> fork map would presume chain features that are not necessarily relevant to the virtual machine, like block reward configurations, or difficulty configurations, for example. This approach allows applications to use advanced opcodes with the fewest number of incidental restrictions. This approach is not without risk or nuance however; without a solid understanding of customizations here, experiments in customization can result in foot shooting.","title":"Running Geth with an External VM"},{"location":"developers/build-from-source/","text":"Dependencies \u00b6 Make sure your system has Go installed. Version 1.15+ is recommended. https://golang.org/doc/install Make sure your system has a C compiler installed. For example, with Linux Ubuntu: $ sudo apt-get install -y build-essential Source \u00b6 Once the dependencies have been installed, it\u2019s time to clone and build the source: $ git clone https://github.com/etclabscore/core-geth.git $ cd core-geth $ make all $ ./build/bin/geth --help Build docker image \u00b6 You can build a local docker image directly from the source: $ git clone https://github.com/etclabscore/core-geth.git $ cd core-geth $ docker build -t = core-geth . Or with all tools: $ docker build -t core-geth-alltools -f Dockerfile.alltools .","title":"Build from source"},{"location":"developers/build-from-source/#dependencies","text":"Make sure your system has Go installed. Version 1.15+ is recommended. https://golang.org/doc/install Make sure your system has a C compiler installed. For example, with Linux Ubuntu: $ sudo apt-get install -y build-essential","title":"Dependencies"},{"location":"developers/build-from-source/#source","text":"Once the dependencies have been installed, it\u2019s time to clone and build the source: $ git clone https://github.com/etclabscore/core-geth.git $ cd core-geth $ make all $ ./build/bin/geth --help","title":"Source"},{"location":"developers/build-from-source/#build-docker-image","text":"You can build a local docker image directly from the source: $ git clone https://github.com/etclabscore/core-geth.git $ cd core-geth $ docker build -t = core-geth . Or with all tools: $ docker build -t core-geth-alltools -f Dockerfile.alltools .","title":"Build docker image"},{"location":"developers/create-new-release/","text":"Developers: How to make a release \u00b6 Decide what the new version should be. In this example, v1.11.16[-stable] will be used. git checkout master make lint and make test are passing on master. This is important because the artifacts to be included with the release will be generated by the CI workflows. If linting or tests fail, the workflows will be interrupted and artifacts will not be generated. git checkout release/v1.11.16 Edit params/version.go making the necessary changes to version information. (To -stable version.) Gotcha: make sure this passes linting, too. git commit -S -s -m \"bump version from v1.11.16-unstable to v1.11.16-stable\" git tag -S -a v1.11.16 git push etclabscore v1.11.16 Push the tag to the remote. I like to do it this way because it triggers the tagged version on CI before the branch/PR version, expediting artifact delivery. Edit params/version.go making the necessary changes to version information. (To -unstable version.) git commit -S -s -m \"bump version from v1.11.16-stable to v1.11.17-unstable\" git push etclabscore Push the branch. This will get PR\u2019d, eg. etclabscore/core-geth!197 Draft a new release, following the existing patterns for naming and notes. https://github.com/etclabscore/core-geth/releases/new Define the tag the release should be associated with (eg v1.11.16 ). Linux, OSX, and Windows artifacts will be uploaded automatically to this release draft by the CI jobs. There should be CI-generated 16 assets total. Note If the release is not drafted manually, it will be automatically drafted by the CI. Await a complete set of uploaded artifacts. If artifacts fail to upload due to issue with the CI jobs, review those jobs to determine if their failure(s) is OK, restarting them if so. Once artifacts have been uploaded and the release draft reviewed by one other person for the following, it\u2019s time to publish! proofreading artifact fingerprint verification notes content approval Once the release is published, merge the associated PR bumping versions.","title":"New release"},{"location":"developers/create-new-release/#developers-how-to-make-a-release","text":"Decide what the new version should be. In this example, v1.11.16[-stable] will be used. git checkout master make lint and make test are passing on master. This is important because the artifacts to be included with the release will be generated by the CI workflows. If linting or tests fail, the workflows will be interrupted and artifacts will not be generated. git checkout release/v1.11.16 Edit params/version.go making the necessary changes to version information. (To -stable version.) Gotcha: make sure this passes linting, too. git commit -S -s -m \"bump version from v1.11.16-unstable to v1.11.16-stable\" git tag -S -a v1.11.16 git push etclabscore v1.11.16 Push the tag to the remote. I like to do it this way because it triggers the tagged version on CI before the branch/PR version, expediting artifact delivery. Edit params/version.go making the necessary changes to version information. (To -unstable version.) git commit -S -s -m \"bump version from v1.11.16-stable to v1.11.17-unstable\" git push etclabscore Push the branch. This will get PR\u2019d, eg. etclabscore/core-geth!197 Draft a new release, following the existing patterns for naming and notes. https://github.com/etclabscore/core-geth/releases/new Define the tag the release should be associated with (eg v1.11.16 ). Linux, OSX, and Windows artifacts will be uploaded automatically to this release draft by the CI jobs. There should be CI-generated 16 assets total. Note If the release is not drafted manually, it will be automatically drafted by the CI. Await a complete set of uploaded artifacts. If artifacts fail to upload due to issue with the CI jobs, review those jobs to determine if their failure(s) is OK, restarting them if so. Once artifacts have been uploaded and the release draft reviewed by one other person for the following, it\u2019s time to publish! proofreading artifact fingerprint verification notes content approval Once the release is published, merge the associated PR bumping versions.","title":"Developers: How to make a release"},{"location":"developers/documentation/","text":"Documentation \u00b6 Project documentation lives in /docs and is written in Markdown . For web-based access, these files are passed through a static site generator MkDocs , specifically MkDocs Material and served via Github Pages. Development \u00b6 You can run a live-reloading web server in imitation of the production generator. To do so: Ensure that your python environment is using python3 and its package manager pip3. You can then install the required mkdocs executable and its dependencies using: python -m pip install -r requirements-mkdocs.txt Run mdkocs serve from the project root. A convenience Make command is likewise provided as make mkdocs-serve . Open http://localhost:8000 in a web browser. Write some docs!","title":"Documentation"},{"location":"developers/documentation/#documentation","text":"Project documentation lives in /docs and is written in Markdown . For web-based access, these files are passed through a static site generator MkDocs , specifically MkDocs Material and served via Github Pages.","title":"Documentation"},{"location":"developers/documentation/#development","text":"You can run a live-reloading web server in imitation of the production generator. To do so: Ensure that your python environment is using python3 and its package manager pip3. You can then install the required mkdocs executable and its dependencies using: python -m pip install -r requirements-mkdocs.txt Run mdkocs serve from the project root. A convenience Make command is likewise provided as make mkdocs-serve . Open http://localhost:8000 in a web browser. Write some docs!","title":"Development"},{"location":"developers/versioning/","text":"Versioning \u00b6 etclabscore/core-geth uses Semantic Versioning . The API definition that would demand increments to the major version is basically nil; it can be expected that a major version bump would be accompanied by an entirely new repository and name. Tagged versions use the suffix -stable and untagged versions (ie everything else) uses the -unstable suffix. See also You can find some historical discussions on versioning at the following links. https://github.com/etclabscore/core-geth/pull/29#issuecomment-588977383 etclabscore/multi-geth-fork#153 https://github.com/etclabscore/core-geth/pull/30#issuecomment-591979271 etclabscore/core-geth#83","title":"Versioning"},{"location":"developers/versioning/#versioning","text":"etclabscore/core-geth uses Semantic Versioning . The API definition that would demand increments to the major version is basically nil; it can be expected that a major version bump would be accompanied by an entirely new repository and name. Tagged versions use the suffix -stable and untagged versions (ie everything else) uses the -unstable suffix. See also You can find some historical discussions on versioning at the following links. https://github.com/etclabscore/core-geth/pull/29#issuecomment-588977383 etclabscore/multi-geth-fork#153 https://github.com/etclabscore/core-geth/pull/30#issuecomment-591979271 etclabscore/core-geth#83","title":"Versioning"},{"location":"getting-started/installation/","text":"Pre-built executable \u00b6 If you just want to download and run geth or any of the other tools here, this is the quickest and simplest way. Binary archives are published at https://github.com/etclabscore/core-geth/releases . Find the latest one for your OS, download it, (check the SHA sum), unarchive it, and run! With Docker \u00b6 All runnable examples below are for images limited to geth . For images including the full suite of tools available from this source, use the Docker Hub tag prefix alltools. , like etclabscore/core-geth:alltools.latest , or the associated Docker file directly ./Dockerfile.alltools . docker run \u00b6 One of the quickest ways to get Ethereum Classic up and running on your machine is by using Docker: $ docker run -d \\ --name core-geth \\ -v $LOCAL_DATADIR :/root \\ -p 30303 :30303 \\ -p 8545 :8545 \\ etclabscore/core-geth \\ --classic \\ --rpc --rpcport 8545 This will start geth in fast-sync mode with a DB memory allowance of 1GB just as the above command does. It will also create a persistent volume in your $LOCAL_DATADIR for saving your blockchain, as well as map the default devp2p and JSON-RPC API ports. Do not forget --http.addr 0.0.0.0 , if you want to access RPC from other containers and/or hosts. By default, geth binds to the local interface and RPC endpoints is not accessible from the outside. docker pull \u00b6 Docker images are automatically published on Docker Hub . Image: latest \u00b6 Image latest is built automatically from the master branch whenever it\u2019s updated. $ docker pull etclabscore/core-geth:latest Image: <tag> \u00b6 Repository tags like v1.2.3 correspond to Docker tags like version-1.2.3 . Example $ docker pull etclabscore/core-geth:version-1.11.1","title":"Installation"},{"location":"getting-started/installation/#pre-built-executable","text":"If you just want to download and run geth or any of the other tools here, this is the quickest and simplest way. Binary archives are published at https://github.com/etclabscore/core-geth/releases . Find the latest one for your OS, download it, (check the SHA sum), unarchive it, and run!","title":"Pre-built executable"},{"location":"getting-started/installation/#with-docker","text":"All runnable examples below are for images limited to geth . For images including the full suite of tools available from this source, use the Docker Hub tag prefix alltools. , like etclabscore/core-geth:alltools.latest , or the associated Docker file directly ./Dockerfile.alltools .","title":"With Docker"},{"location":"getting-started/installation/#docker-run","text":"One of the quickest ways to get Ethereum Classic up and running on your machine is by using Docker: $ docker run -d \\ --name core-geth \\ -v $LOCAL_DATADIR :/root \\ -p 30303 :30303 \\ -p 8545 :8545 \\ etclabscore/core-geth \\ --classic \\ --rpc --rpcport 8545 This will start geth in fast-sync mode with a DB memory allowance of 1GB just as the above command does. It will also create a persistent volume in your $LOCAL_DATADIR for saving your blockchain, as well as map the default devp2p and JSON-RPC API ports. Do not forget --http.addr 0.0.0.0 , if you want to access RPC from other containers and/or hosts. By default, geth binds to the local interface and RPC endpoints is not accessible from the outside.","title":"docker run"},{"location":"getting-started/installation/#docker-pull","text":"Docker images are automatically published on Docker Hub .","title":"docker pull"},{"location":"getting-started/installation/#image-latest","text":"Image latest is built automatically from the master branch whenever it\u2019s updated. $ docker pull etclabscore/core-geth:latest","title":"Image: latest"},{"location":"getting-started/installation/#image-tag","text":"Repository tags like v1.2.3 correspond to Docker tags like version-1.2.3 . Example $ docker pull etclabscore/core-geth:version-1.11.1","title":"Image: &lt;tag&gt;"},{"location":"getting-started/run-cli/","text":"Running geth \u00b6 Use for Ethereum mainnet While core-geth is mainly used for the Ethereum Classic network, you can use it for Ethereum mainnet and other supported networks as well. Fast node on an Ethereum Classic network \u00b6 By far the most common scenario is people wanting to simply interact with the Ethereum network: create accounts; transfer funds; deploy and interact with contracts. For this particular use-case the user doesn\u2019t care about years-old historical data, so we can fast-sync quickly to the current state of the network. To do so: $ geth [|--classic|--social|--ethersocial|--mix|--music|--testnet|--rinkeby|--kotti|--goerli|--mordor] console This command will: Start geth in fast sync mode (default, can be changed with the --syncmode flag), causing it to download more data in exchange for avoiding processing the entire history of the Ethereum network, which is very CPU intensive. Start up geth \u2018s built-in interactive JavaScript console , (via the trailing console subcommand) through which you can invoke all official web3 methods as well as geth \u2018s own management APIs . This tool is optional and if you leave it out you can always attach to an already running geth instance with geth attach . A Full node on the Mordor test network \u00b6 Transitioning towards developers, if you\u2019d like to play around with creating Ethereum contracts, you almost certainly would like to do that without any real money involved until you get the hang of the entire system. In other words, instead of attaching to the main network, you want to join the mordor test network with your node, which is fully equivalent to the main network, but with play-Ether only. $ geth --mordor console The console subcommand has the exact same meaning as above and they are equally useful on the testnet too. Please see above for their explanations if you\u2019ve skipped here. Specifying the --mordor flag, however, will reconfigure your geth instance a bit: Instead of using the default data directory ( ~/.ethereum on Linux for example), geth will nest itself one level deeper into a mordor subfolder ( ~/.ethereum/mordor on Linux). Note, on OSX and Linux this also means that attaching to a running testnet node requires the use of a custom endpoint since geth attach will try to attach to a production node endpoint by default. E.g. geth attach <datadir>/mordor/geth.ipc . Windows users are not affected by this. Instead of connecting the main Ethereum network, the client will connect to the mordor\u2019s test network, which uses different P2P bootnodes, different network IDs and genesis states. Note Although there are some internal protective measures to prevent transactions from crossing over between the classic network and test network, you should make sure to always use separate accounts for play-money and real-money. Unless you manually move accounts, geth will by default correctly separate the two networks and will not make any accounts available between them.* Configuration \u00b6 As an alternative to passing the numerous flags to the geth binary, you can also pass a configuration file via: $ geth --config /path/to/your_config.toml To get an idea how the file should look like you can use the dumpconfig subcommand to export your existing configuration: $ geth --your-favourite-flags dumpconfig Note This works only with geth v1.6.0 and above.* Command-line Options \u00b6 $ geth --help NAME: geth - the ETC Core Go-Ethereum command line interface Copyright 2013-2019 The go-ethereum Authors USAGE: geth [options] command [command options] [arguments...] VERSION: 1.11.21-unstable COMMANDS: account Manage accounts attach Start an interactive JavaScript environment (connect to node) console Start an interactive JavaScript environment copydb Create a local chain from a target chaindata folder dump Dump a specific block from storage dumpconfig Show configuration values dumpgenesis Dumps genesis block JSON configuration to stdout export Export blockchain into file export-preimages Export the preimage database into an RLP stream import Import a blockchain file import-preimages Import the preimage database from an RLP stream init Bootstrap and initialize a new genesis block inspect Inspect the storage size for each type of data in the database js Execute the specified JavaScript files license Display license information makecache Generate ethash verification cache (for testing) makedag Generate ethash mining DAG (for testing) removedb Remove blockchain and state databases show-deprecated-flags Show flags that have been deprecated version Print version numbers version-check Checks (online) whether the current version suffers from any known security vulnerabilities wallet Manage Ethereum presale wallets help, h Shows a list of commands or help for one command ETHEREUM OPTIONS: --config value TOML configuration file --datadir value Data directory for the databases and keystore (default: \"/Users/ziogaschr/Library/Ethereum\") --datadir.ancient value Data directory for ancient chain segments (default = inside chaindata) --ancient.rpc value Connect to a remote freezer via RPC. Value must an HTTP(S), WS(S), unix socket, or 'stdio' URL. Incompatible with --datadir.ancient --keystore value Directory for the keystore (default = inside the datadir) --nousb Disables monitoring for and managing USB hardware wallets --pcscdpath value Path to the smartcard daemon (pcscd) socket file --networkid value Explicitly set network id (integer)(For testnets: use --ropsten, --rinkeby, --goerli, --kotti, --mordor, --yolov2 instead) (default: 1) --classic Ethereum Classic network: pre-configured Ethereum Classic mainnet --mordor Mordor network: Ethereum Classic's cross-client proof-of-work test network --social Ethereum Social network: pre-configured Ethereum Social mainnet --mix MIX network: pre-configured MIX mainnet --ethersocial Ethersocial network: pre-configured Ethersocial mainnet --rinkeby Rinkeby network: pre-configured proof-of-authority test network --kotti Kotti network: cross-client proof-of-authority test network --goerli G\u00f6rli network: pre-configured proof-of-authority test network --rinkeby Rinkeby network: pre-configured proof-of-authority test network --yolov2 YOLOv2 network: pre-configured proof-of-authority shortlived test network. --ropsten Ropsten network: pre-configured proof-of-work test network --syncmode value Blockchain sync mode (\"fast\", \"full\", or \"light\") (default: fast) --exitwhensynced Exits after block synchronisation completes --gcmode value Blockchain garbage collection mode (\"full\", \"archive\") (default: \"full\") --txlookuplimit value Number of recent blocks to maintain transactions index by-hash for (default = index all blocks) (default: 0) --ethstats value Reporting URL of a ethstats service (nodename:secret@host:port) --identity value Custom node name --lightkdf Reduce key-derivation RAM & CPU usage at some expense of KDF strength --whitelist value Comma separated block number-to-hash mappings to enforce (<number>=<hash>) --ecbp1100 value Configure ECBP-1100 (MESS) block activation number (default: 18446744073709551615) LIGHT CLIENT OPTIONS: --light.serve value Maximum percentage of time allowed for serving LES requests (multi-threaded processing allows values over 100) (default: 0) --light.ingress value Incoming bandwidth limit for serving light clients (kilobytes/sec, 0 = unlimited) (default: 0) --light.egress value Outgoing bandwidth limit for serving light clients (kilobytes/sec, 0 = unlimited) (default: 0) --light.maxpeers value Maximum number of light clients to serve, or light servers to attach to (default: 100) --ulc.servers value List of trusted ultra-light servers --ulc.fraction value Minimum % of trusted ultra-light servers required to announce a new head (default: 75) --ulc.onlyannounce Ultra light server sends announcements only --light.nopruning Disable ancient light chain data pruning DEVELOPER CHAIN OPTIONS: --dev Ephemeral proof-of-authority network with a pre-funded developer account, mining enabled --dev.period value Block period for proof-of-authority network to use in developer mode (0 = mine only if transaction pending) (default: 0) --dev.pow Ephemeral proof-of-work network with a pre-funded developer account, mining enabled ETHASH OPTIONS: --ethash.cachedir value Directory to store the ethash verification caches (default = inside the datadir) --ethash.cachesinmem value Number of recent ethash caches to keep in memory (16MB each) (default: 2) --ethash.cachesondisk value Number of recent ethash caches to keep on disk (16MB each) (default: 3) --ethash.cacheslockmmap Lock memory maps of recent ethash caches --ethash.dagdir value Directory to store the ethash mining DAGs (default: \"/Users/ziogaschr/Library/Ethash\") --ethash.dagsinmem value Number of recent ethash mining DAGs to keep in memory (1+GB each) (default: 1) --ethash.dagsondisk value Number of recent ethash mining DAGs to keep on disk (1+GB each) (default: 2) --ethash.dagslockmmap Lock memory maps for recent ethash mining DAGs TRANSACTION POOL OPTIONS: --txpool.locals value Comma separated accounts to treat as locals (no flush, priority inclusion) --txpool.nolocals Disables price exemptions for locally submitted transactions --txpool.journal value Disk journal for local transaction to survive node restarts (default: \"transactions.rlp\") --txpool.rejournal value Time interval to regenerate the local transaction journal (default: 1h0m0s) --txpool.pricelimit value Minimum gas price limit to enforce for acceptance into the pool (default: 1) --txpool.pricebump value Price bump percentage to replace an already existing transaction (default: 10) --txpool.accountslots value Minimum number of executable transaction slots guaranteed per account (default: 16) --txpool.globalslots value Maximum number of executable transaction slots for all accounts (default: 4096) --txpool.accountqueue value Maximum number of non-executable transaction slots permitted per account (default: 64) --txpool.globalqueue value Maximum number of non-executable transaction slots for all accounts (default: 1024) --txpool.lifetime value Maximum amount of time non-executable transaction are queued (default: 3h0m0s) PERFORMANCE TUNING OPTIONS: --cache value Megabytes of memory allocated to internal caching (default = 4096 mainnet full node, 128 light mode) (default: 1024) --cache.database value Percentage of cache memory allowance to use for database io (default: 50) --cache.trie value Percentage of cache memory allowance to use for trie caching (default = 15% full mode, 30% archive mode) (default: 15) --cache.trie.journal value Disk journal directory for trie cache to survive node restarts (default: \"triecache\") --cache.trie.rejournal value Time interval to regenerate the trie cache journal (default: 1h0m0s) --cache.gc value Percentage of cache memory allowance to use for trie pruning (default = 25% full mode, 0% archive mode) (default: 25) --cache.snapshot value Percentage of cache memory allowance to use for snapshot caching (default = 10% full mode, 20% archive mode) (default: 10) --cache.noprefetch Disable heuristic state prefetch during block import (less CPU and disk IO, more time waiting for data) --cache.preimages Enable recording the SHA3/keccak preimages of trie keys (default: true) ACCOUNT OPTIONS: --unlock value Comma separated list of accounts to unlock --password value Password file to use for non-interactive password input --signer value External signer (url or path to ipc file) --allow-insecure-unlock Allow insecure account unlocking when account-related RPCs are exposed by http API AND CONSOLE OPTIONS: --ipcdisable Disable the IPC-RPC server --ipcpath value Filename for IPC socket/pipe within the datadir (explicit paths escape it) --http Enable the HTTP-RPC server --http.addr value HTTP-RPC server listening interface (default: \"localhost\") --http.port value HTTP-RPC server listening port (default: 8545) --http.api value API's offered over the HTTP-RPC interface --http.corsdomain value Comma separated list of domains from which to accept cross origin requests (browser enforced) --http.vhosts value Comma separated list of virtual hostnames from which to accept requests (server enforced). Accepts '*' wildcard. (default: \"localhost\") --ws Enable the WS-RPC server --ws.addr value WS-RPC server listening interface (default: \"localhost\") --ws.port value WS-RPC server listening port (default: 8546) --ws.api value API's offered over the WS-RPC interface --ws.origins value Origins from which to accept websockets requests --graphql Enable GraphQL on the HTTP-RPC server. Note that GraphQL can only be started if an HTTP server is started as well. --graphql.corsdomain value Comma separated list of domains from which to accept cross origin requests (browser enforced) --graphql.vhosts value Comma separated list of virtual hostnames from which to accept requests (server enforced). Accepts '*' wildcard. (default: \"localhost\") --rpc.gascap value Sets a cap on gas that can be used in eth_call/estimateGas (0=infinite) (default: 25000000) --rpc.txfeecap value Sets a cap on transaction fee (in ether) that can be sent via the RPC APIs (0 = no cap) (default: 1) --jspath loadScript JavaScript root path for loadScript (default: \".\") --exec value Execute JavaScript statement --preload value Comma separated list of JavaScript files to preload into the console NETWORKING OPTIONS: --bootnodes value Comma separated enode URLs for P2P discovery bootstrap --bootnodesv4 value Comma separated enode URLs for P2P v4 discovery bootstrap (light server, full nodes) (deprecated, use --bootnodes) --bootnodesv5 value Comma separated enode URLs for P2P v5 discovery bootstrap (light server, light nodes) (deprecated, use --bootnodes) --discovery.dns value Sets DNS discovery entry points (use \"\" to disable DNS) --eth.protocols value Sets the Ethereum Protocol versions (65|64|63) (default = 65,64,63 first is primary) --port value Network listening port (default: 30303) --maxpeers value Maximum number of network peers (network disabled if set to 0) (default: 50) --maxpendpeers value Maximum number of pending connection attempts (defaults used if set to 0) (default: 0) --nat value NAT port mapping mechanism (any|none|upnp|pmp|extip:<IP>) (default: \"any\") --nodiscover Disables the peer discovery mechanism (manual peer addition) --v5disc Enables the experimental RLPx V5 (Topic Discovery) mechanism --netrestrict value Restricts network communication to the given IP networks (CIDR masks) --nodekey value P2P node key file --nodekeyhex value P2P node key as hex (for testing) MINER OPTIONS: --mine Enable mining --miner.threads value Number of CPU threads to use for mining (default: 0) --miner.notify value Comma separated HTTP URL list to notify of new work packages --miner.gasprice value Minimum gas price for mining a transaction (default: 1000000000) --miner.gastarget value Target gas floor for mined blocks (default: 8000000) --miner.gaslimit value Target gas ceiling for mined blocks (default: 8000000) --miner.etherbase value Public address for block mining rewards (default = first account) (default: \"0\") --miner.extradata value Block extra data set by the miner (default = client version) --miner.recommit value Time interval to recreate the block being mined (default: 3s) --miner.noverify Disable remote sealing verification GAS PRICE ORACLE OPTIONS: --gpo.blocks value Number of recent blocks to check for gas prices (default: 20) --gpo.percentile value Suggested gas price is the given percentile of a set of recent transaction gas prices (default: 60) --gpo.maxprice value Maximum gas price will be recommended by gpo (default: 500000000000) VIRTUAL MACHINE OPTIONS: --vmdebug Record information useful for VM and contract debugging --vm.evm value External EVM configuration (default = built-in interpreter) --vm.ewasm value External ewasm configuration (default = built-in interpreter) LOGGING AND DEBUGGING OPTIONS: --fakepow Disables proof-of-work verification --fakepow.poisson Disables proof-of-work verification and adds mining delay (Poisson) based on --miner.threads --nocompaction Disables db compaction after import --verbosity value Logging verbosity: 0=silent, 1=error, 2=warn, 3=info, 4=debug, 5=detail (default: 3) --vmodule value Per-module verbosity: comma-separated list of <pattern>=<level> (e.g. eth/*=5,p2p=4) --backtrace value Request a stack trace at a specific logging statement (e.g. \"block.go:271\") --debug Prepends log messages with call-site location (file and line number) --pprof Enable the pprof HTTP server --pprof.addr value pprof HTTP server listening interface (default: \"127.0.0.1\") --pprof.port value pprof HTTP server listening port (default: 6060) --pprof.memprofilerate value Turn on memory profiling with the given rate (default: 524288) --pprof.blockprofilerate value Turn on block profiling with the given rate (default: 0) --pprof.cpuprofile value Write CPU profile to the given file --trace value Write execution trace to the given file METRICS AND STATS OPTIONS: --metrics Enable metrics collection and reporting --metrics.expensive Enable expensive metrics collection and reporting --metrics.addr value Enable stand-alone metrics HTTP server listening interface (default: \"127.0.0.1\") --metrics.port value Metrics HTTP server listening port (default: 6060) --metrics.influxdb Enable metrics export/push to an external InfluxDB database --metrics.influxdb.endpoint value InfluxDB API endpoint to report metrics to (default: \"http://localhost:8086\") --metrics.influxdb.database value InfluxDB database name to push reported metrics to (default: \"geth\") --metrics.influxdb.username value Username to authorize access to the database (default: \"test\") --metrics.influxdb.password value Password to authorize access to the database (default: \"test\") --metrics.influxdb.tags value Comma-separated InfluxDB tags (key/values) attached to all measurements (default: \"host=localhost\") WHISPER (deprecated) OPTIONS: --shh Enable Whisper --shh.maxmessagesize value Max message size accepted (default: 1048576) --shh.pow value Minimum POW accepted (default: 0.2) --shh.restrict-light Restrict connection between two whisper light clients ALIASED (deprecated) OPTIONS: --rpc Enable the HTTP-RPC server (deprecated, use --http) --rpcaddr value HTTP-RPC server listening interface (deprecated, use --http.addr) (default: \"localhost\") --rpcport value HTTP-RPC server listening port (deprecated, use --http.port) (default: 8545) --rpccorsdomain value Comma separated list of domains from which to accept cross origin requests (browser enforced) (deprecated, use --http.corsdomain) --rpcvhosts value Comma separated list of virtual hostnames from which to accept requests (server enforced). Accepts '*' wildcard. (deprecated, use --http.vhosts) (default: \"localhost\") --rpcapi value API's offered over the HTTP-RPC interface (deprecated, use --http.api) --wsaddr value WS-RPC server listening interface (deprecated, use --ws.addr) (default: \"localhost\") --wsport value WS-RPC server listening port (deprecated, use --ws.port) (default: 8546) --wsorigins value Origins from which to accept websockets requests (deprecated, use --ws.origins) --wsapi value API's offered over the WS-RPC interface (deprecated, use --ws.api) --gpoblocks value Number of recent blocks to check for gas prices (deprecated, use --gpo.blocks) (default: 20) --gpopercentile value Suggested gas price is the given percentile of a set of recent transaction gas prices (deprecated, use --gpo.percentile) (default: 60) --graphql.addr value GraphQL server listening interface (deprecated, graphql can only be enabled on the HTTP-RPC server endpoint, use --graphql) --graphql.port value GraphQL server listening port (deprecated, graphql can only be enabled on the HTTP-RPC server endpoint, use --graphql) (default: 8545) --pprofport value pprof HTTP server listening port (deprecated, use --pprof.port) (default: 6060) --pprofaddr value pprof HTTP server listening interface (deprecated, use --pprof.addr) (default: \"127.0.0.1\") --memprofilerate value Turn on memory profiling with the given rate (deprecated, use --pprof.memprofilerate) (default: 524288) --blockprofilerate value Turn on block profiling with the given rate (deprecated, use --pprof.blockprofilerate) (default: 0) --cpuprofile value Write CPU profile to the given file (deprecated, use --pprof.cpuprofile) MISC OPTIONS: --snapshot Enables snapshot-database mode -- experimental work in progress feature --help, -h show help COPYRIGHT: Copyright 2013-2020 The core-geth and go-ethereum Authors","title":"CLI"},{"location":"getting-started/run-cli/#running-geth","text":"Use for Ethereum mainnet While core-geth is mainly used for the Ethereum Classic network, you can use it for Ethereum mainnet and other supported networks as well.","title":"Running geth"},{"location":"getting-started/run-cli/#fast-node-on-an-ethereum-classic-network","text":"By far the most common scenario is people wanting to simply interact with the Ethereum network: create accounts; transfer funds; deploy and interact with contracts. For this particular use-case the user doesn\u2019t care about years-old historical data, so we can fast-sync quickly to the current state of the network. To do so: $ geth [|--classic|--social|--ethersocial|--mix|--music|--testnet|--rinkeby|--kotti|--goerli|--mordor] console This command will: Start geth in fast sync mode (default, can be changed with the --syncmode flag), causing it to download more data in exchange for avoiding processing the entire history of the Ethereum network, which is very CPU intensive. Start up geth \u2018s built-in interactive JavaScript console , (via the trailing console subcommand) through which you can invoke all official web3 methods as well as geth \u2018s own management APIs . This tool is optional and if you leave it out you can always attach to an already running geth instance with geth attach .","title":"Fast node on an Ethereum Classic network"},{"location":"getting-started/run-cli/#a-full-node-on-the-mordor-test-network","text":"Transitioning towards developers, if you\u2019d like to play around with creating Ethereum contracts, you almost certainly would like to do that without any real money involved until you get the hang of the entire system. In other words, instead of attaching to the main network, you want to join the mordor test network with your node, which is fully equivalent to the main network, but with play-Ether only. $ geth --mordor console The console subcommand has the exact same meaning as above and they are equally useful on the testnet too. Please see above for their explanations if you\u2019ve skipped here. Specifying the --mordor flag, however, will reconfigure your geth instance a bit: Instead of using the default data directory ( ~/.ethereum on Linux for example), geth will nest itself one level deeper into a mordor subfolder ( ~/.ethereum/mordor on Linux). Note, on OSX and Linux this also means that attaching to a running testnet node requires the use of a custom endpoint since geth attach will try to attach to a production node endpoint by default. E.g. geth attach <datadir>/mordor/geth.ipc . Windows users are not affected by this. Instead of connecting the main Ethereum network, the client will connect to the mordor\u2019s test network, which uses different P2P bootnodes, different network IDs and genesis states. Note Although there are some internal protective measures to prevent transactions from crossing over between the classic network and test network, you should make sure to always use separate accounts for play-money and real-money. Unless you manually move accounts, geth will by default correctly separate the two networks and will not make any accounts available between them.*","title":"A Full node on the Mordor test network"},{"location":"getting-started/run-cli/#configuration","text":"As an alternative to passing the numerous flags to the geth binary, you can also pass a configuration file via: $ geth --config /path/to/your_config.toml To get an idea how the file should look like you can use the dumpconfig subcommand to export your existing configuration: $ geth --your-favourite-flags dumpconfig Note This works only with geth v1.6.0 and above.*","title":"Configuration"},{"location":"getting-started/run-cli/#command-line-options","text":"$ geth --help NAME: geth - the ETC Core Go-Ethereum command line interface Copyright 2013-2019 The go-ethereum Authors USAGE: geth [options] command [command options] [arguments...] VERSION: 1.11.21-unstable COMMANDS: account Manage accounts attach Start an interactive JavaScript environment (connect to node) console Start an interactive JavaScript environment copydb Create a local chain from a target chaindata folder dump Dump a specific block from storage dumpconfig Show configuration values dumpgenesis Dumps genesis block JSON configuration to stdout export Export blockchain into file export-preimages Export the preimage database into an RLP stream import Import a blockchain file import-preimages Import the preimage database from an RLP stream init Bootstrap and initialize a new genesis block inspect Inspect the storage size for each type of data in the database js Execute the specified JavaScript files license Display license information makecache Generate ethash verification cache (for testing) makedag Generate ethash mining DAG (for testing) removedb Remove blockchain and state databases show-deprecated-flags Show flags that have been deprecated version Print version numbers version-check Checks (online) whether the current version suffers from any known security vulnerabilities wallet Manage Ethereum presale wallets help, h Shows a list of commands or help for one command ETHEREUM OPTIONS: --config value TOML configuration file --datadir value Data directory for the databases and keystore (default: \"/Users/ziogaschr/Library/Ethereum\") --datadir.ancient value Data directory for ancient chain segments (default = inside chaindata) --ancient.rpc value Connect to a remote freezer via RPC. Value must an HTTP(S), WS(S), unix socket, or 'stdio' URL. Incompatible with --datadir.ancient --keystore value Directory for the keystore (default = inside the datadir) --nousb Disables monitoring for and managing USB hardware wallets --pcscdpath value Path to the smartcard daemon (pcscd) socket file --networkid value Explicitly set network id (integer)(For testnets: use --ropsten, --rinkeby, --goerli, --kotti, --mordor, --yolov2 instead) (default: 1) --classic Ethereum Classic network: pre-configured Ethereum Classic mainnet --mordor Mordor network: Ethereum Classic's cross-client proof-of-work test network --social Ethereum Social network: pre-configured Ethereum Social mainnet --mix MIX network: pre-configured MIX mainnet --ethersocial Ethersocial network: pre-configured Ethersocial mainnet --rinkeby Rinkeby network: pre-configured proof-of-authority test network --kotti Kotti network: cross-client proof-of-authority test network --goerli G\u00f6rli network: pre-configured proof-of-authority test network --rinkeby Rinkeby network: pre-configured proof-of-authority test network --yolov2 YOLOv2 network: pre-configured proof-of-authority shortlived test network. --ropsten Ropsten network: pre-configured proof-of-work test network --syncmode value Blockchain sync mode (\"fast\", \"full\", or \"light\") (default: fast) --exitwhensynced Exits after block synchronisation completes --gcmode value Blockchain garbage collection mode (\"full\", \"archive\") (default: \"full\") --txlookuplimit value Number of recent blocks to maintain transactions index by-hash for (default = index all blocks) (default: 0) --ethstats value Reporting URL of a ethstats service (nodename:secret@host:port) --identity value Custom node name --lightkdf Reduce key-derivation RAM & CPU usage at some expense of KDF strength --whitelist value Comma separated block number-to-hash mappings to enforce (<number>=<hash>) --ecbp1100 value Configure ECBP-1100 (MESS) block activation number (default: 18446744073709551615) LIGHT CLIENT OPTIONS: --light.serve value Maximum percentage of time allowed for serving LES requests (multi-threaded processing allows values over 100) (default: 0) --light.ingress value Incoming bandwidth limit for serving light clients (kilobytes/sec, 0 = unlimited) (default: 0) --light.egress value Outgoing bandwidth limit for serving light clients (kilobytes/sec, 0 = unlimited) (default: 0) --light.maxpeers value Maximum number of light clients to serve, or light servers to attach to (default: 100) --ulc.servers value List of trusted ultra-light servers --ulc.fraction value Minimum % of trusted ultra-light servers required to announce a new head (default: 75) --ulc.onlyannounce Ultra light server sends announcements only --light.nopruning Disable ancient light chain data pruning DEVELOPER CHAIN OPTIONS: --dev Ephemeral proof-of-authority network with a pre-funded developer account, mining enabled --dev.period value Block period for proof-of-authority network to use in developer mode (0 = mine only if transaction pending) (default: 0) --dev.pow Ephemeral proof-of-work network with a pre-funded developer account, mining enabled ETHASH OPTIONS: --ethash.cachedir value Directory to store the ethash verification caches (default = inside the datadir) --ethash.cachesinmem value Number of recent ethash caches to keep in memory (16MB each) (default: 2) --ethash.cachesondisk value Number of recent ethash caches to keep on disk (16MB each) (default: 3) --ethash.cacheslockmmap Lock memory maps of recent ethash caches --ethash.dagdir value Directory to store the ethash mining DAGs (default: \"/Users/ziogaschr/Library/Ethash\") --ethash.dagsinmem value Number of recent ethash mining DAGs to keep in memory (1+GB each) (default: 1) --ethash.dagsondisk value Number of recent ethash mining DAGs to keep on disk (1+GB each) (default: 2) --ethash.dagslockmmap Lock memory maps for recent ethash mining DAGs TRANSACTION POOL OPTIONS: --txpool.locals value Comma separated accounts to treat as locals (no flush, priority inclusion) --txpool.nolocals Disables price exemptions for locally submitted transactions --txpool.journal value Disk journal for local transaction to survive node restarts (default: \"transactions.rlp\") --txpool.rejournal value Time interval to regenerate the local transaction journal (default: 1h0m0s) --txpool.pricelimit value Minimum gas price limit to enforce for acceptance into the pool (default: 1) --txpool.pricebump value Price bump percentage to replace an already existing transaction (default: 10) --txpool.accountslots value Minimum number of executable transaction slots guaranteed per account (default: 16) --txpool.globalslots value Maximum number of executable transaction slots for all accounts (default: 4096) --txpool.accountqueue value Maximum number of non-executable transaction slots permitted per account (default: 64) --txpool.globalqueue value Maximum number of non-executable transaction slots for all accounts (default: 1024) --txpool.lifetime value Maximum amount of time non-executable transaction are queued (default: 3h0m0s) PERFORMANCE TUNING OPTIONS: --cache value Megabytes of memory allocated to internal caching (default = 4096 mainnet full node, 128 light mode) (default: 1024) --cache.database value Percentage of cache memory allowance to use for database io (default: 50) --cache.trie value Percentage of cache memory allowance to use for trie caching (default = 15% full mode, 30% archive mode) (default: 15) --cache.trie.journal value Disk journal directory for trie cache to survive node restarts (default: \"triecache\") --cache.trie.rejournal value Time interval to regenerate the trie cache journal (default: 1h0m0s) --cache.gc value Percentage of cache memory allowance to use for trie pruning (default = 25% full mode, 0% archive mode) (default: 25) --cache.snapshot value Percentage of cache memory allowance to use for snapshot caching (default = 10% full mode, 20% archive mode) (default: 10) --cache.noprefetch Disable heuristic state prefetch during block import (less CPU and disk IO, more time waiting for data) --cache.preimages Enable recording the SHA3/keccak preimages of trie keys (default: true) ACCOUNT OPTIONS: --unlock value Comma separated list of accounts to unlock --password value Password file to use for non-interactive password input --signer value External signer (url or path to ipc file) --allow-insecure-unlock Allow insecure account unlocking when account-related RPCs are exposed by http API AND CONSOLE OPTIONS: --ipcdisable Disable the IPC-RPC server --ipcpath value Filename for IPC socket/pipe within the datadir (explicit paths escape it) --http Enable the HTTP-RPC server --http.addr value HTTP-RPC server listening interface (default: \"localhost\") --http.port value HTTP-RPC server listening port (default: 8545) --http.api value API's offered over the HTTP-RPC interface --http.corsdomain value Comma separated list of domains from which to accept cross origin requests (browser enforced) --http.vhosts value Comma separated list of virtual hostnames from which to accept requests (server enforced). Accepts '*' wildcard. (default: \"localhost\") --ws Enable the WS-RPC server --ws.addr value WS-RPC server listening interface (default: \"localhost\") --ws.port value WS-RPC server listening port (default: 8546) --ws.api value API's offered over the WS-RPC interface --ws.origins value Origins from which to accept websockets requests --graphql Enable GraphQL on the HTTP-RPC server. Note that GraphQL can only be started if an HTTP server is started as well. --graphql.corsdomain value Comma separated list of domains from which to accept cross origin requests (browser enforced) --graphql.vhosts value Comma separated list of virtual hostnames from which to accept requests (server enforced). Accepts '*' wildcard. (default: \"localhost\") --rpc.gascap value Sets a cap on gas that can be used in eth_call/estimateGas (0=infinite) (default: 25000000) --rpc.txfeecap value Sets a cap on transaction fee (in ether) that can be sent via the RPC APIs (0 = no cap) (default: 1) --jspath loadScript JavaScript root path for loadScript (default: \".\") --exec value Execute JavaScript statement --preload value Comma separated list of JavaScript files to preload into the console NETWORKING OPTIONS: --bootnodes value Comma separated enode URLs for P2P discovery bootstrap --bootnodesv4 value Comma separated enode URLs for P2P v4 discovery bootstrap (light server, full nodes) (deprecated, use --bootnodes) --bootnodesv5 value Comma separated enode URLs for P2P v5 discovery bootstrap (light server, light nodes) (deprecated, use --bootnodes) --discovery.dns value Sets DNS discovery entry points (use \"\" to disable DNS) --eth.protocols value Sets the Ethereum Protocol versions (65|64|63) (default = 65,64,63 first is primary) --port value Network listening port (default: 30303) --maxpeers value Maximum number of network peers (network disabled if set to 0) (default: 50) --maxpendpeers value Maximum number of pending connection attempts (defaults used if set to 0) (default: 0) --nat value NAT port mapping mechanism (any|none|upnp|pmp|extip:<IP>) (default: \"any\") --nodiscover Disables the peer discovery mechanism (manual peer addition) --v5disc Enables the experimental RLPx V5 (Topic Discovery) mechanism --netrestrict value Restricts network communication to the given IP networks (CIDR masks) --nodekey value P2P node key file --nodekeyhex value P2P node key as hex (for testing) MINER OPTIONS: --mine Enable mining --miner.threads value Number of CPU threads to use for mining (default: 0) --miner.notify value Comma separated HTTP URL list to notify of new work packages --miner.gasprice value Minimum gas price for mining a transaction (default: 1000000000) --miner.gastarget value Target gas floor for mined blocks (default: 8000000) --miner.gaslimit value Target gas ceiling for mined blocks (default: 8000000) --miner.etherbase value Public address for block mining rewards (default = first account) (default: \"0\") --miner.extradata value Block extra data set by the miner (default = client version) --miner.recommit value Time interval to recreate the block being mined (default: 3s) --miner.noverify Disable remote sealing verification GAS PRICE ORACLE OPTIONS: --gpo.blocks value Number of recent blocks to check for gas prices (default: 20) --gpo.percentile value Suggested gas price is the given percentile of a set of recent transaction gas prices (default: 60) --gpo.maxprice value Maximum gas price will be recommended by gpo (default: 500000000000) VIRTUAL MACHINE OPTIONS: --vmdebug Record information useful for VM and contract debugging --vm.evm value External EVM configuration (default = built-in interpreter) --vm.ewasm value External ewasm configuration (default = built-in interpreter) LOGGING AND DEBUGGING OPTIONS: --fakepow Disables proof-of-work verification --fakepow.poisson Disables proof-of-work verification and adds mining delay (Poisson) based on --miner.threads --nocompaction Disables db compaction after import --verbosity value Logging verbosity: 0=silent, 1=error, 2=warn, 3=info, 4=debug, 5=detail (default: 3) --vmodule value Per-module verbosity: comma-separated list of <pattern>=<level> (e.g. eth/*=5,p2p=4) --backtrace value Request a stack trace at a specific logging statement (e.g. \"block.go:271\") --debug Prepends log messages with call-site location (file and line number) --pprof Enable the pprof HTTP server --pprof.addr value pprof HTTP server listening interface (default: \"127.0.0.1\") --pprof.port value pprof HTTP server listening port (default: 6060) --pprof.memprofilerate value Turn on memory profiling with the given rate (default: 524288) --pprof.blockprofilerate value Turn on block profiling with the given rate (default: 0) --pprof.cpuprofile value Write CPU profile to the given file --trace value Write execution trace to the given file METRICS AND STATS OPTIONS: --metrics Enable metrics collection and reporting --metrics.expensive Enable expensive metrics collection and reporting --metrics.addr value Enable stand-alone metrics HTTP server listening interface (default: \"127.0.0.1\") --metrics.port value Metrics HTTP server listening port (default: 6060) --metrics.influxdb Enable metrics export/push to an external InfluxDB database --metrics.influxdb.endpoint value InfluxDB API endpoint to report metrics to (default: \"http://localhost:8086\") --metrics.influxdb.database value InfluxDB database name to push reported metrics to (default: \"geth\") --metrics.influxdb.username value Username to authorize access to the database (default: \"test\") --metrics.influxdb.password value Password to authorize access to the database (default: \"test\") --metrics.influxdb.tags value Comma-separated InfluxDB tags (key/values) attached to all measurements (default: \"host=localhost\") WHISPER (deprecated) OPTIONS: --shh Enable Whisper --shh.maxmessagesize value Max message size accepted (default: 1048576) --shh.pow value Minimum POW accepted (default: 0.2) --shh.restrict-light Restrict connection between two whisper light clients ALIASED (deprecated) OPTIONS: --rpc Enable the HTTP-RPC server (deprecated, use --http) --rpcaddr value HTTP-RPC server listening interface (deprecated, use --http.addr) (default: \"localhost\") --rpcport value HTTP-RPC server listening port (deprecated, use --http.port) (default: 8545) --rpccorsdomain value Comma separated list of domains from which to accept cross origin requests (browser enforced) (deprecated, use --http.corsdomain) --rpcvhosts value Comma separated list of virtual hostnames from which to accept requests (server enforced). Accepts '*' wildcard. (deprecated, use --http.vhosts) (default: \"localhost\") --rpcapi value API's offered over the HTTP-RPC interface (deprecated, use --http.api) --wsaddr value WS-RPC server listening interface (deprecated, use --ws.addr) (default: \"localhost\") --wsport value WS-RPC server listening port (deprecated, use --ws.port) (default: 8546) --wsorigins value Origins from which to accept websockets requests (deprecated, use --ws.origins) --wsapi value API's offered over the WS-RPC interface (deprecated, use --ws.api) --gpoblocks value Number of recent blocks to check for gas prices (deprecated, use --gpo.blocks) (default: 20) --gpopercentile value Suggested gas price is the given percentile of a set of recent transaction gas prices (deprecated, use --gpo.percentile) (default: 60) --graphql.addr value GraphQL server listening interface (deprecated, graphql can only be enabled on the HTTP-RPC server endpoint, use --graphql) --graphql.port value GraphQL server listening port (deprecated, graphql can only be enabled on the HTTP-RPC server endpoint, use --graphql) (default: 8545) --pprofport value pprof HTTP server listening port (deprecated, use --pprof.port) (default: 6060) --pprofaddr value pprof HTTP server listening interface (deprecated, use --pprof.addr) (default: \"127.0.0.1\") --memprofilerate value Turn on memory profiling with the given rate (deprecated, use --pprof.memprofilerate) (default: 524288) --blockprofilerate value Turn on block profiling with the given rate (deprecated, use --pprof.blockprofilerate) (default: 0) --cpuprofile value Write CPU profile to the given file (deprecated, use --pprof.cpuprofile) MISC OPTIONS: --snapshot Enables snapshot-database mode -- experimental work in progress feature --help, -h show help COPYRIGHT: Copyright 2013-2020 The core-geth and go-ethereum Authors","title":"Command-line Options"},{"location":"tutorials/private-network/","text":"Tutorial: Operating a Private Network \u00b6 Operating a private network \u00b6 Maintaining your own private network is more involved as a lot of configurations taken for granted in the official networks need to be manually set up. Defining the private genesis state \u00b6 First, you\u2019ll need to create the genesis state of your networks, which all nodes need to be aware of and agree upon. This consists of a small JSON file (e.g. call it genesis.json ): { \"config\" : { \"chainId\" : <arbi trar y posi t ive i nte ger> , \"homesteadBlock\" : 0 , \"eip150Block\" : 0 , \"eip155Block\" : 0 , \"eip158Block\" : 0 , \"byzantiumBlock\" : 0 , \"constantinopleBlock\" : 0 , \"petersburgBlock\" : 0 }, \"alloc\" : {}, \"coinbase\" : \"0x0000000000000000000000000000000000000000\" , \"difficulty\" : \"0x20000\" , \"extraData\" : \"\" , \"gasLimit\" : \"0x2fefd8\" , \"nonce\" : \"0x0000000000000042\" , \"mixhash\" : \"0x0000000000000000000000000000000000000000000000000000000000000000\" , \"parentHash\" : \"0x0000000000000000000000000000000000000000000000000000000000000000\" , \"timestamp\" : \"0x00\" } The above fields should be fine for most purposes, although we\u2019d recommend changing the nonce to some random value so you prevent unknown remote nodes from being able to connect to you. If you\u2019d like to pre-fund some accounts for easier testing, create the accounts and populate the alloc field with their addresses. \"alloc\" : { \"0x0000000000000000000000000000000000000001\" : { \"balance\" : \"111111111\" }, \"0x0000000000000000000000000000000000000002\" : { \"balance\" : \"222222222\" } } With the genesis state defined in the above JSON file, you\u2019ll need to initialize every geth node with it prior to starting it up to ensure all blockchain parameters are correctly set: $ geth init path/to/genesis.json Creating the rendezvous point \u00b6 With all nodes that you want to run initialized to the desired genesis state, you\u2019ll need to start a bootstrap node that others can use to find each other in your network and/or over the internet. The clean way is to configure and run a dedicated bootnode: $ bootnode --genkey = boot.key $ bootnode --nodekey = boot.key With the bootnode online, it will display an enode URL that other nodes can use to connect to it and exchange peer information. Make sure to replace the displayed IP address information (most probably [::] ) with your externally accessible IP to get the actual enode URL. Note You could also use a full-fledged geth node as a bootnode, but it\u2019s the less recommended way. Starting up your member nodes \u00b6 With the bootnode operational and externally reachable (you can try telnet <ip> <port> to ensure it\u2019s indeed reachable), start every subsequent geth node pointed to the bootnode for peer discovery via the --bootnodes flag. It will probably also be desirable to keep the data directory of your private network separated, so do also specify a custom --datadir flag. $ geth --datadir = path/to/custom/data/folder --bootnodes = <bootnode-enode-url-from-above> Note Since your network will be completely cut off from the main and test networks, you\u2019ll also need to configure a miner to process transactions and create new blocks for you. Running a private miner \u00b6 Mining on the public Ethereum network is a complex task as it\u2019s only feasible using GPUs, requiring an OpenCL or CUDA enabled ethminer instance. For information on such a setup, please consult the EtherMining subreddit and the ethminer repository. In a private network setting, however a single CPU miner instance is more than enough for practical purposes as it can produce a stable stream of blocks at the correct intervals without needing heavy resources (consider running on a single thread, no need for multiple ones either). To start a geth instance for mining, run it with all your usual flags, extended by: $ geth <usual-flags> --mine --miner.threads = 1 --etherbase = 0x0000000000000000000000000000000000000000 Which will start mining blocks and transactions on a single CPU thread, crediting all proceedings to the account specified by --etherbase . You can further tune the mining by changing the default gas limit blocks converge to ( --targetgaslimit ) and the price transactions are accepted at ( --gasprice ).","title":"Setup private network"},{"location":"tutorials/private-network/#tutorial-operating-a-private-network","text":"","title":"Tutorial: Operating a Private Network"},{"location":"tutorials/private-network/#operating-a-private-network","text":"Maintaining your own private network is more involved as a lot of configurations taken for granted in the official networks need to be manually set up.","title":"Operating a private network"},{"location":"tutorials/private-network/#defining-the-private-genesis-state","text":"First, you\u2019ll need to create the genesis state of your networks, which all nodes need to be aware of and agree upon. This consists of a small JSON file (e.g. call it genesis.json ): { \"config\" : { \"chainId\" : <arbi trar y posi t ive i nte ger> , \"homesteadBlock\" : 0 , \"eip150Block\" : 0 , \"eip155Block\" : 0 , \"eip158Block\" : 0 , \"byzantiumBlock\" : 0 , \"constantinopleBlock\" : 0 , \"petersburgBlock\" : 0 }, \"alloc\" : {}, \"coinbase\" : \"0x0000000000000000000000000000000000000000\" , \"difficulty\" : \"0x20000\" , \"extraData\" : \"\" , \"gasLimit\" : \"0x2fefd8\" , \"nonce\" : \"0x0000000000000042\" , \"mixhash\" : \"0x0000000000000000000000000000000000000000000000000000000000000000\" , \"parentHash\" : \"0x0000000000000000000000000000000000000000000000000000000000000000\" , \"timestamp\" : \"0x00\" } The above fields should be fine for most purposes, although we\u2019d recommend changing the nonce to some random value so you prevent unknown remote nodes from being able to connect to you. If you\u2019d like to pre-fund some accounts for easier testing, create the accounts and populate the alloc field with their addresses. \"alloc\" : { \"0x0000000000000000000000000000000000000001\" : { \"balance\" : \"111111111\" }, \"0x0000000000000000000000000000000000000002\" : { \"balance\" : \"222222222\" } } With the genesis state defined in the above JSON file, you\u2019ll need to initialize every geth node with it prior to starting it up to ensure all blockchain parameters are correctly set: $ geth init path/to/genesis.json","title":"Defining the private genesis state"},{"location":"tutorials/private-network/#creating-the-rendezvous-point","text":"With all nodes that you want to run initialized to the desired genesis state, you\u2019ll need to start a bootstrap node that others can use to find each other in your network and/or over the internet. The clean way is to configure and run a dedicated bootnode: $ bootnode --genkey = boot.key $ bootnode --nodekey = boot.key With the bootnode online, it will display an enode URL that other nodes can use to connect to it and exchange peer information. Make sure to replace the displayed IP address information (most probably [::] ) with your externally accessible IP to get the actual enode URL. Note You could also use a full-fledged geth node as a bootnode, but it\u2019s the less recommended way.","title":"Creating the rendezvous point"},{"location":"tutorials/private-network/#starting-up-your-member-nodes","text":"With the bootnode operational and externally reachable (you can try telnet <ip> <port> to ensure it\u2019s indeed reachable), start every subsequent geth node pointed to the bootnode for peer discovery via the --bootnodes flag. It will probably also be desirable to keep the data directory of your private network separated, so do also specify a custom --datadir flag. $ geth --datadir = path/to/custom/data/folder --bootnodes = <bootnode-enode-url-from-above> Note Since your network will be completely cut off from the main and test networks, you\u2019ll also need to configure a miner to process transactions and create new blocks for you.","title":"Starting up your member nodes"},{"location":"tutorials/private-network/#running-a-private-miner","text":"Mining on the public Ethereum network is a complex task as it\u2019s only feasible using GPUs, requiring an OpenCL or CUDA enabled ethminer instance. For information on such a setup, please consult the EtherMining subreddit and the ethminer repository. In a private network setting, however a single CPU miner instance is more than enough for practical purposes as it can produce a stable stream of blocks at the correct intervals without needing heavy resources (consider running on a single thread, no need for multiple ones either). To start a geth instance for mining, run it with all your usual flags, extended by: $ geth <usual-flags> --mine --miner.threads = 1 --etherbase = 0x0000000000000000000000000000000000000000 Which will start mining blocks and transactions on a single CPU thread, crediting all proceedings to the account specified by --etherbase . You can further tune the mining by changing the default gas limit blocks converge to ( --targetgaslimit ) and the price transactions are accepted at ( --gasprice ).","title":"Running a private miner"}]}